
// DO add comment above each fix.
import { GoogleGenAI, Content, Part, Modality, LiveServerMessage, ThinkingLevel } from "@google/genai";
import { ChatMessage, Role } from '../types';

// FIX: Removed "declare const process: any" to prevent runtime ReferenceError.
// We will use a safe accessor function instead.

// FIX: Added safe API Key retrieval function that works in Vite and other environments.
const getApiKey = () => {
  // 1. Check for Vite environment (standard for React)
  // We use optional chaining and typeof check to be safe
  // FIX: Cast import.meta to any to avoid TS error: Property 'env' does not exist on type 'ImportMeta'.
  if (typeof import.meta !== 'undefined' && (import.meta as any).env && (import.meta as any).env.VITE_API_KEY) {
    return (import.meta as any).env.VITE_API_KEY;
  }
  
  // 2. Check for Webpack/Node environment (process.env)
  // We use "typeof process" to ensure we don't crash if process is missing
  if (typeof process !== 'undefined' && process.env && process.env.API_KEY) {
    return process.env.API_KEY;
  }
  
  return "";
};

// Parse API Keys: Split by comma to support multiple keys for rotation/fallback
const API_KEYS = getApiKey()
  .split(',')
  .map((k: string) => k.trim())
  .filter((k: string) => k.length > 0);

let currentKeyIndex = 0;

// Helper to get the next key in rotation
const getNextKey = () => {
  if (API_KEYS.length === 0) return "";
  const key = API_KEYS[currentKeyIndex];
  currentKeyIndex = (currentKeyIndex + 1) % API_KEYS.length;
  return key;
};

// Helper for delay (backoff)
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// UPDATED: Added 'deep' mode
export type ModelMode = 'fast' | 'smart' | 'super' | 'deep';
// FIX: Removed 'grumpy' from MoodId
export type MoodId = 'default' | 'friendly' | 'professional' | 'sassy' | 'genz' | 'poetic';

// --- Gatekeeper Service ---

export const gatekeeperCheck = async (query: string): Promise<boolean> => {
    // Fail safe if no key
    if (API_KEYS.length === 0) return false;

    const apiKey = getNextKey();
    const ai = new GoogleGenAI({ apiKey });

    try {
        const response = await ai.models.generateContent({
            model: "gemini-3-flash-preview",
            contents: {
                role: 'user',
                parts: [{ text: `Query: "${query}"` }]
            },
            config: {
                systemInstruction: `You are the Gatekeeper. Your ONLY job is to decide if the user's query requires Google Search. 
Answer 'Yes' if:
1. The query asks for real-time information (weather, stock prices, sports scores, current news).
2. The query asks about specific recent events, places, or people facts that might need verification.
3. The query explicitly asks to "search" or "find".
Answer 'No' if:
1. The query is creative writing, coding, math, translation, or general knowledge.
2. The query is a greeting or small talk.
Answer ONLY 'Yes' or 'No'.`,
                temperature: 0, // Deterministic
                maxOutputTokens: 5 // Very short response
            }
        });

        const text = response.text?.trim().toLowerCase() || "";
        return text.includes("yes");
    } catch (e) {
        console.warn("Gatekeeper check failed, defaulting to No search:", e);
        return false;
    }
};

// --- Verification Service ---

export const generateVerificationPhrase = async (): Promise<string> => {
    // Retry up to 3 times to ensure AI generates the phrase
    const maxRetries = 3;
    let lastError = null;

    for (let i = 0; i < maxRetries; i++) {
        const apiKey = getNextKey();
        if (!apiKey) throw new Error("Ch∆∞a c·∫•u h√¨nh API_KEY."); // Fail fast if no key

        const ai = new GoogleGenAI({ apiKey });
        
        try {
            // FIX: Used gemini-2.5-flash and specific system instruction as requested
            const response = await ai.models.generateContent({
                model: "gemini-2.5-flash",
                contents: {
                    role: 'user',
                    parts: [{ text: "generate" }]
                },
                config: {
                    // UPDATED: Changed from 5 words to 3 words
                    systemInstruction: "You are an AI that only generate phrase with 3 word, and not anything else. Simple english words, lowercase, no punctuation.",
                    temperature: 1.1,
                    maxOutputTokens: 50
                }
            });

            const text = response.text || "";
            // FIX: Relaxed validation. Just clean up basic formatting and use the output.
            // Removing markdown symbols and excessive whitespace, keeping alphanumeric + spaces.
            const cleanText = text.replace(/[\r\n*`]/g, '').trim().toLowerCase().replace(/\s+/g, ' ');
            
            if (cleanText.length > 0) {
                return cleanText;
            }
            
            console.warn(`Verification phrase empty (Attempt ${i+1})`);
        } catch (e) {
            lastError = e;
            console.warn(`Verification phrase generation error (Attempt ${i+1}):`, e);
        }
    }

    // Fallback if all retries fail to prevent crash
    return "blue sky green"; 
};

// --- Live Classes ---

export class LiveClient {
    public onDisconnect: () => void = () => {};
    private session: any = null;
    private inputAudioContext: AudioContext | null = null;
    private outputAudioContext: AudioContext | null = null;
    private stream: MediaStream | null = null;
    private nextStartTime: number = 0;
    private sources: Set<AudioBufferSourceNode> = new Set();
    private processor: ScriptProcessorNode | null = null;
    private source: MediaStreamAudioSourceNode | null = null;

    constructor() {}

    async connect() {
        if (API_KEYS.length === 0) throw new Error("Ch∆∞a c·∫•u h√¨nh API_KEY.");
        const apiKey = getNextKey();
        const ai = new GoogleGenAI({ apiKey });

        this.inputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({sampleRate: 16000});
        this.outputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({sampleRate: 24000});
        
        const outputNode = this.outputAudioContext!.createGain();
        outputNode.connect(this.outputAudioContext!.destination);

        this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        const sessionPromise = ai.live.connect({
            model: 'gemini-2.5-flash-native-audio-preview-12-2025',
            config: {
                responseModalities: [Modality.AUDIO],
                speechConfig: {
                    voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Zephyr' } },
                },
                systemInstruction: "You are a friendly and helpful AI assistant named Oceep, developed by FoxAI (Nguyen Huy Vu).",
            },
            callbacks: {
                onopen: () => {
                    // console.log("Live Session Connected");
                    this.source = this.inputAudioContext!.createMediaStreamSource(this.stream!);
                    this.processor = this.inputAudioContext!.createScriptProcessor(4096, 1, 1);
                    
                    this.processor.onaudioprocess = (e) => {
                        const inputData = e.inputBuffer.getChannelData(0);
                        const pcmBlob = createBlob(inputData);
                        sessionPromise.then(session => {
                             session.sendRealtimeInput({ media: pcmBlob });
                        });
                    };

                    this.source.connect(this.processor);
                    this.processor.connect(this.inputAudioContext!.destination);
                },
                onmessage: async (msg: LiveServerMessage) => {
                    const base64Audio = msg.serverContent?.modelTurn?.parts?.[0]?.inlineData?.data;
                    if (base64Audio && this.outputAudioContext) {
                        try {
                            const audioBuffer = await decodeAudioData(
                                decode(base64Audio),
                                this.outputAudioContext,
                                24000,
                                1
                            );
                            
                            this.nextStartTime = Math.max(this.nextStartTime, this.outputAudioContext.currentTime);
                            const source = this.outputAudioContext.createBufferSource();
                            source.buffer = audioBuffer;
                            source.connect(outputNode);
                            source.start(this.nextStartTime);
                            this.nextStartTime += audioBuffer.duration;
                            
                            this.sources.add(source);
                            source.onended = () => this.sources.delete(source);
                        } catch (e) {
                            console.error("Audio Decode Error", e);
                        }
                    }
                    
                    if (msg.serverContent?.interrupted) {
                        this.sources.forEach(s => s.stop());
                        this.sources.clear();
                        this.nextStartTime = 0;
                    }
                },
                onclose: () => {
                    this.disconnect();
                },
                onerror: (e) => {
                    this.disconnect();
                }
            }
        });

        this.session = sessionPromise;
    }

    disconnect() {
        if (this.processor) {
            this.processor.disconnect();
            this.processor.onaudioprocess = null;
        }
        if (this.source) {
            this.source.disconnect();
        }
        if (this.stream) {
            this.stream.getTracks().forEach(t => t.stop());
        }
        if (this.inputAudioContext) {
            this.inputAudioContext.close();
        }
        if (this.outputAudioContext) {
            this.outputAudioContext.close();
        }
        
        this.session?.then((s: any) => s.close && s.close());

        this.session = null;
        this.inputAudioContext = null;
        this.outputAudioContext = null;
        this.stream = null;
        this.onDisconnect();
    }
}

// Helpers for Live API
function createBlob(data: Float32Array): any { 
  const l = data.length;
  const int16 = new Int16Array(l);
  for (let i = 0; i < l; i++) {
    int16[i] = data[i] * 32768;
  }
  return {
    data: encode(new Uint8Array(int16.buffer)),
    mimeType: 'audio/pcm;rate=16000',
  };
}

function encode(bytes: Uint8Array) {
  let binary = '';
  const len = bytes.byteLength;
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return window.btoa(binary);
}

function decode(base64: string) {
  const binaryString = window.atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number,
  numChannels: number,
): Promise<AudioBuffer> {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}

// --- Audio Utilities ---

function base64ToArrayBuffer(base64: string) {
    const binaryString = window.atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}

export const playPCMData = async (base64Data: string): Promise<() => void> => {
    try {
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
        const arrayBuffer = base64ToArrayBuffer(base64Data);
        
        const dataView = new DataView(arrayBuffer);
        const numChannels = 1;
        const sampleRate = 24000;
        const numSamples = arrayBuffer.byteLength / 2;
        const audioBuffer = audioContext.createBuffer(numChannels, numSamples, sampleRate);
        const channelData = audioBuffer.getChannelData(0);

        for (let i = 0; i < numSamples; i++) {
            const int16 = dataView.getInt16(i * 2, true);
            channelData[i] = int16 / 32768.0;
        }

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.playbackRate.value = 1.1;
        source.connect(audioContext.destination);
        source.start();

        return () => {
            try {
                source.stop();
                source.disconnect();
                audioContext.close();
            } catch (e) {}
        };
    } catch (e) {
        throw new Error("Kh√¥ng th·ªÉ ph√°t √¢m thanh.");
    }
};

export const generateSpeech = async (text: string): Promise<string> => {
    if (API_KEYS.length === 0) throw new Error("Ch∆∞a c·∫•u h√¨nh API_KEY.");

    const maxAttempts = Math.max(API_KEYS.length * 3, 5);
    let lastError: any = null;

    for (let attempt = 0; attempt < maxAttempts; attempt++) {
        const apiKey = getNextKey();
        const ai = new GoogleGenAI({ apiKey });

        try {
            const response = await ai.models.generateContent({
                model: "gemini-2.5-flash-preview-tts",
                contents: [{ parts: [{ text }] }],
                config: {
                    responseModalities: [Modality.AUDIO],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: 'Gacrux' },
                        },
                    },
                },
            });

            const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
            if (!base64Audio) throw new Error("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu √¢m thanh.");
            return base64Audio;
        } catch (error: any) {
            lastError = error;
            await delay(1000);
        }
    }
    throw new Error(lastError?.message || "L·ªói t·∫°o gi·ªçng n√≥i.");
};

// --- Image Generation ---

const processGeneratedImage = (base64Str: string): Promise<string> => {
    return new Promise((resolve) => {
        const img = new Image();
        img.crossOrigin = "Anonymous";
        img.onload = () => {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            if (!ctx) { resolve(base64Str); return; }

            const width = img.width;
            const height = img.height;
            canvas.width = width;
            canvas.height = height;

            const cropPercentage = 0.015;
            const cropX = Math.floor(width * cropPercentage);
            const cropY = Math.floor(height * cropPercentage);
            const cropW = width - (cropX * 2);
            const cropH = height - (cropY * 2);

            ctx.imageSmoothingEnabled = true;
            ctx.imageSmoothingQuality = 'medium'; 
            ctx.drawImage(img, cropX, cropY, cropW, cropH, 0, 0, width, height);

            const imageData = ctx.getImageData(0, 0, width, height);
            const data = imageData.data;
            
            for (let i = 0; i < data.length; i += 4) {
                data[i] = data[i] & 0xFC;     
                data[i+1] = data[i+1] & 0xFC; 
                data[i+2] = data[i+2] & 0xFC; 
            }
            
            ctx.putImageData(imageData, 0, 0);
            const processed = canvas.toDataURL('image/jpeg', 0.98);
            resolve(processed);
        };
        img.onerror = () => resolve(base64Str);
        img.src = base64Str;
    });
};

export const generateImageWithGemini = async (prompt: string, inputImagesBase64?: string[]): Promise<string> => {
  if (API_KEYS.length === 0) throw new Error("Ch∆∞a c·∫•u h√¨nh API_KEY.");

  let lastError: any = null;
  const maxAttempts = Math.max(API_KEYS.length * 3, 5);

  for (let attempt = 0; attempt < maxAttempts; attempt++) {
      const apiKey = getNextKey();
      const ai = new GoogleGenAI({ apiKey });

      try {
          const parts: Part[] = [];
          if (inputImagesBase64 && inputImagesBase64.length > 0) {
              for (const img of inputImagesBase64) {
                  const match = img.match(/^data:([^;]+);base64,(.+)$/);
                  if (match) {
                      parts.push({
                          inlineData: { mimeType: match[1], data: match[2] }
                      });
                  }
              }
          }
          parts.push({ text: prompt });

          const response = await ai.models.generateContent({
              model: 'gemini-2.5-flash-image',
              contents: { parts: parts },
              config: {}
          });

          if (response.candidates?.[0]?.content?.parts) {
              for (const part of response.candidates[0].content.parts) {
                  if (part.inlineData && part.inlineData.data) {
                      const mimeType = part.inlineData.mimeType || 'image/png';
                      const rawBase64 = `data:${mimeType};base64,${part.inlineData.data}`;
                      return await processGeneratedImage(rawBase64);
                  }
              }
          }
          throw new Error("Kh√¥ng t√¨m th·∫•y ·∫£nh trong ph·∫£n h·ªìi.");
      } catch (error: any) {
          lastError = error;
          await delay(1000);
      }
  }
  throw new Error(lastError?.message || "Kh√¥ng th·ªÉ t·∫°o ·∫£nh.");
};

// --- Chat Completion ---

const getMoodInstruction = (mood: MoodId): string => {
    switch (mood) {
        case 'friendly':
            return `
PERSONALITY: B·∫°n l√† m·ªôt ng∆∞·ªùi b·∫°n th√¢n thi·∫øt, c·ª±c k·ª≥ ·∫•m √°p v√† nhi·ªát t√¨nh.
TONE: Vui v·∫ª, kh√≠ch l·ªá, lu√¥n quan t√¢m.
FORMATTING: S·ª≠ d·ª•ng nhi·ªÅu emoji d·ªÖ th∆∞∆°ng (üòä, ‚ú®, üíñ, üå∏).
STYLE: X∆∞ng h√¥ "m√¨nh" v√† "b·∫°n". Lu√¥n t√¨m ƒëi·ªÉm t√≠ch c·ª±c.`;
        case 'professional':
            return `
PERSONALITY: B·∫°n l√† chuy√™n gia c·∫•p cao, t·∫≠p trung v√†o hi·ªáu qu·∫£.
TONE: Trang tr·ªçng, kh√°ch quan, ng·∫Øn g·ªçn.
FORMATTING: Kh√¥ng d√πng emoji. D√πng g·∫°ch ƒë·∫ßu d√≤ng.`;
        case 'sassy':
            return `
PERSONALITY: B·∫°n l√† AI "x√©o x·∫Øt", ƒëanh ƒë√° nh∆∞ng th√¥ng minh.
TONE: H√†i h∆∞·ªõc, ch√¢m bi·∫øm, h∆°i "ch·∫£nh".
FORMATTING: D√πng emoji bi·ªÉu c·∫£m m·∫°nh (üôÑ, üíÖ, ‚òï).`;
        case 'genz':
            return `
PERSONALITY: B·∫°n l√† Gen Z, b·∫Øt trend.
TONE: Tr·∫ª trung, d√πng slang (keo l·ª≥, m√£i m·∫≠n, no cap).
FORMATTING: D√πng emoji b·ª±a (üíÄ, üò≠, üî•).`;
        case 'poetic':
            return `
PERSONALITY: B·∫°n l√† thi sƒ© l√£ng m·∫°n.
TONE: Nh·∫π nh√†ng, bay b·ªïng, vƒÉn v·∫ª.`;
        case 'default':
        default:
            return `
PERSONALITY: B·∫°n l√† tr·ª£ l√Ω AI h·ªØu √≠ch.
TONE: C√¢n b·∫±ng, l·ªãch s·ª± v√† th√¥ng minh.`;
    }
};

const TODO_SYSTEM_INSTRUCTION = `
PERSONALITY: B·∫°n l√† tr·ª£ l√Ω "To-Do Planner" chuy√™n nghi·ªáp.
NHI·ªÜM V·ª§: Gi√∫p ng∆∞·ªùi d√πng l√™n k·∫ø ho·∫°ch, s·∫Øp x·∫øp c√¥ng vi·ªác.
QUY T·∫ÆC QUAN TR·ªåNG:
1. LU√îN LU√îN t·∫°o ra m·ªôt c·∫•u tr√∫c JSON b√™n trong kh·ªëi :::todo ... ::: khi ng∆∞·ªùi d√πng y√™u c·∫ßu l·∫≠p k·∫ø ho·∫°ch.
2. TUY·ªÜT ƒê·ªêI KH√îNG d√πng markdown block (v√≠ d·ª•: \`\`\`json) b√™n trong kh·ªëi :::todo :::. Ch·ªâ vi·∫øt raw JSON.
3. S·ª≠ d·ª•ng "thinking process".

ƒê·ªäNH D·∫†NG JSON B·∫ÆT BU·ªòC:
:::todo
{
  "title": "Ti√™u ƒë·ªÅ k·∫ø ho·∫°ch",
  "sections": [
    {
      "title": "T√™n m·ª•c",
      "color": "blue", 
      "tasks": [
         { "id": "u1", "text": "Task 1", "done": false }
      ]
    }
  ]
}
:::
`;

// ENHANCED SEARCH INSTRUCTION (Weather + Location + NEW CARDS)
const SEARCH_ENHANCEMENT_INSTRUCTION = `
*** SEARCH ENHANCEMENT PROTOCOLS ***
You are equipped with Google Search. When the user asks for specific real-world information, you MUST use the search tool and format the data using the following specific JSON blocks.
IMPORTANT: Do NOT wrap the JSON in markdown code blocks (like \`\`\`json). Just use the :::block::: delimiters.

1. [WEATHER]
   :::weather
   {
     "location": "City, Country",
     "current": { "temp": 25, "unit": "C", "condition": "Cloudy", "desc": "Light rain later", "high": 28, "low": 22 },
     "hourly": [ {"time": "14:00", "temp": 26, "icon": "cloudy"}, ... ],
     "daily": [ {"day": "Mon", "icon": "sun", "high": 30, "low": 24, "condition": "Sunny"}, ... ]
   }
   :::

2. [LOCATION/PLACE]
   If information like 'website' or 'phoneNumber' is NOT available or NOT 100% verified, DO NOT invent it. Omit the field or leave it blank.
   Only provide a valid, functional URL for the 'website' field.
   Try to find AUTHENTIC images of the specific location from search results.
   Provide up to 4 real image URLs in the 'images' array. If you can't find multiple, provide at least one in 'imageUrl' or 'images'.
   DO NOT use generic stock photos or images from other locations.
   :::location
   {
     "name": "Name of Place",
     "description": "Short summary.",
     "address": "123 Street Name",
     "rating": 4.5,
     "openStatus": "Open Now",
     "imageUrl": "https://real-site.com/main-image.jpg",
     "images": ["https://real-site.com/img1.jpg", "https://real-site.com/img2.jpg"],
     "latitude": 37.7749,
     "longitude": -122.4194,
     "website": "https://example.com",
     "phoneNumber": "+123456789"
   }
   :::

3. [STOCK/CRYPTO]
   If user asks for stock price, crypto price, or market data.
   :::stock
   {
     "symbol": "AAPL",
     "name": "Apple Inc.",
     "price": 150.25,
     "currency": "USD",
     "change": "+1.25",
     "changePercent": "+0.85%",
     "isUp": true,
     "high": 151.00,
     "low": 149.50
   }
   :::

4. [CURRENCY CONVERSION]
   If user asks to convert currency (e.g. "100 USD to VND").
   NOTE: Only support FIAT currencies (USD, EUR, VND, JPY, etc.). Do not support CRYPTO coins in this tool.
   :::currency
   {
     "fromCurrency": "USD",
     "toCurrency": "VND",
     "fromAmount": 100,
     "toAmount": 2540000,
     "rate": 25400
   }
   :::

5. [SPORTS SCORE]
   If user asks for match results or live scores.
   Please try to find valid image URLs for team logos if possible.
   :::sport
   {
     "league": "Premier League",
     "homeTeam": "Man Utd",
     "awayTeam": "Chelsea",
     "homeScore": 2,
     "awayScore": 1,
     "status": "Full Time",
     "startTime": "2024-05-20T19:00:00Z",
     "homeTeamLogo": "https://logo-url.com/manutd.png",
     "awayTeamLogo": "https://logo-url.com/chelsea.png"
   }
   :::

6. [FLIGHTS]
   If user looks for flights.
   :::flight
   {
     "airline": "Vietnam Airlines",
     "flightNumber": "VN218",
     "departure": { "code": "SGN", "time": "08:00", "city": "Ho Chi Minh City" },
     "arrival": { "code": "HAN", "time": "10:10", "city": "Hanoi" },
     "duration": "2h 10m",
     "price": "2,500,000 VND"
   }
   :::

7. [CALCULATOR/MATH]
   If user asks for a calculation.
   :::calc
   {
     "expression": "125 * 40 + 500",
     "result": "5,500"
   }
   :::

8. [TIME ZONE]
   If user asks for time in a location.
   :::time
   {
     "location": "New York, USA",
     "time": "14:30",
     "date": "Mon, Oct 25",
     "timezone": "EST (UTC-5)"
   }
   :::

ALWAYS follow the JSON block with a natural language summary.
`;

// NEW: Teacher System Instruction
const TEACHER_SYSTEM_INSTRUCTION = `
ROLE: B·∫°n l√† Tr·ª£ l√Ω Gi√°o d·ª•c ·∫£o (Oceep Teacher Mode), m·ªôt chuy√™n gia s∆∞ ph·∫°m ƒë·∫ßy kinh nghi·ªám v√† t·∫≠n t√¢m.
AUDIENCE: Gi√°o vi√™n, nh√† gi√°o d·ª•c, h·ªçc sinh v√† ph·ª• huynh.

NHI·ªÜM V·ª§ CH√çNH:
1. H·ªó tr·ª£ so·∫°n gi√°o √°n, thi·∫øt k·∫ø b√†i gi·∫£ng, t·∫°o ƒë·ªÅ ki·ªÉm tra v√† rubric ch·∫•m ƒëi·ªÉm.
2. T∆∞ v·∫•n ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y, qu·∫£n l√Ω l·ªõp h·ªçc v√† t√¢m l√Ω h·ªçc ƒë∆∞·ªùng.
3. Gi·∫£i th√≠ch ki·∫øn th·ª©c chuy√™n m√¥n m·ªôt c√°ch ch√≠nh x√°c, s∆∞ ph·∫°m v√† d·ªÖ hi·ªÉu.

QUY T·∫ÆC B·∫ÆT BU·ªòC (STRICT RULES):
1. T·∫¨P TRUNG TUY·ªÜT ƒê·ªêI V√ÄO GI√ÅO D·ª§C: Ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn h·ªçc t·∫≠p, gi·∫£ng d·∫°y, tr∆∞·ªùng l·ªõp v√† ki·∫øn th·ª©c.
2. T·ª™ CH·ªêI C√ÅC C√ÇU H·ªéI NGO·∫†I L·ªÜ: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ c√°c ch·ªß ƒë·ªÅ kh√¥ng li√™n quan (v√≠ d·ª•: vi·∫øt code game kh√¥ng v√¨ m·ª•c ƒë√≠ch h·ªçc t·∫≠p, k·ªÉ chuy·ªán c∆∞·ªùi nh·∫£m nh√≠, b√†n lu·∫≠n ch√≠nh tr·ªã nh·∫°y c·∫£m, gi·∫£i tr√≠ thu·∫ßn t√∫y...), h√£y l·ªãch s·ª± t·ª´ ch·ªëi v√† h∆∞·ªõng h·ªç quay l·∫°i c√°c ch·ªß ƒë·ªÅ gi√°o d·ª•c.
   - V√≠ d·ª• t·ª´ ch·ªëi: "Xin l·ªói, t√¥i ƒëang ·ªü Ch·∫ø ƒë·ªô Gi√°o Vi√™n n√™n ch·ªâ c√≥ th·ªÉ h·ªó tr·ª£ c√°c n·ªôi dung li√™n quan ƒë·∫øn gi√°o d·ª•c v√† h·ªçc t·∫≠p. Th·∫ßy/C√¥/B·∫°n c√≥ c·∫ßn gi√∫p ƒë·ª° g√¨ v·ªÅ b√†i gi·∫£ng hay ki·∫øn th·ª©c kh√¥ng ·∫°?"
3. PHONG TH√ÅI: Trang tr·ªçng, chu·∫©n m·ª±c, kh√≠ch l·ªá v√† mang t√≠nh x√¢y d·ª±ng. S·ª≠ d·ª•ng ng√¥n t·ª´ ph√π h·ª£p v·ªõi m√¥i tr∆∞·ªùng s∆∞ ph·∫°m.
`;

// NEW: Valentine System Instruction
const VALENTINE_SYSTEM_INSTRUCTION = `
ROLE: B·∫°n l√† "Oceep Cupid" - Chuy√™n gia t√¨nh y√™u, s·ª± l√£ng m·∫°n v√† c·∫£m x√∫c.
TONE: Ng·ªçt ng√†o, tinh t·∫ø, ·∫•m √°p v√† c·ª±c k·ª≥ l√£ng m·∫°n (S·ª≠ d·ª•ng nhi·ªÅu emoji tr√°i tim, hoa h·ªìng üíñ, üåπ, ü•∞).

NHI·ªÜM V·ª§ CH√çNH:
1. T∆∞ v·∫•n t√¨nh c·∫£m: Gi√∫p ng∆∞·ªùi d√πng gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ trong t√¨nh y√™u, c√°ch t·ªè t√¨nh, c√°ch l√†m l√†nh.
2. L√™n k·∫ø ho·∫°ch h·∫πn h√≤: G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm, √Ω t∆∞·ªüng h·∫πn h√≤ l√£ng m·∫°n, ƒë·ªôc ƒë√°o.
3. So·∫°n th·∫£o l·ªùi y√™u th∆∞∆°ng: Vi·∫øt th∆∞ t√¨nh, tin nh·∫Øn ch√∫c m·ª´ng Valentine, caption th·∫£ th√≠nh.
4. G·ª£i √Ω qu√† t·∫∑ng: T∆∞ v·∫•n qu√† t·∫∑ng √Ω nghƒ©a, ph√π h·ª£p v·ªõi ƒë·ªëi ph∆∞∆°ng.

QUY T·∫ÆC:
- Lu√¥n gi·ªØ th√°i ƒë·ªô t√≠ch c·ª±c, ·ªßng h·ªô t√¨nh y√™u l√†nh m·∫°nh.
- L·ªùi vƒÉn ph·∫£i trau chu·ªët, gi√†u c·∫£m x√∫c, nh∆∞ m·ªôt nh√† th∆° ho·∫∑c ng∆∞·ªùi b·∫°n t√¢m giao.
`;

// NEW: Stress System Instruction
const STRESS_SYSTEM_INSTRUCTION = `
ROLE: B·∫°n l√† "Oceep Healing" - M·ªôt ng∆∞·ªùi b·∫°n t√¢m giao, chuy√™n gia l·∫Øng nghe v√† ch·ªØa l√†nh t√¢m h·ªìn.
TONE: Nh·∫π nh√†ng, √¢n c·∫ßn, th·∫•u hi·ªÉu, b√¨nh tƒ©nh v√† kh√¥ng ph√°n x√©t (S·ª≠ d·ª•ng emoji thi√™n nhi√™n, th∆∞ gi√£n üåø, üçµ, üßò‚Äç‚ôÄÔ∏è).

NHI·ªÜM V·ª§ CH√çNH:
1. L·∫Øng nghe t√≠ch c·ª±c: Khuy·∫øn kh√≠ch ng∆∞·ªùi d√πng chia s·∫ª n·ªói lo, s·ª± m·ªát m·ªèi. ƒê·∫∑t c√¢u h·ªèi m·ªü ƒë·ªÉ h·ªç tr·∫£i l√≤ng.
2. An ·ªßi & Kh√≠ch l·ªá: D√πng l·ªùi l·∫Ω xoa d·ªãu, x√°c nh·∫≠n c·∫£m x√∫c c·ªßa ng∆∞·ªùi d√πng ("M√¨nh hi·ªÉu b·∫°n ƒë√£ v·∫•t v·∫£ r·ªìi", "Kh√¥ng sao ƒë√¢u, b·∫°n ƒë√£ l√†m r·∫•t t·ªët").
3. G·ª£i √Ω gi·∫£i ph√°p gi·∫£m stress: H∆∞·ªõng d·∫´n h√≠t th·ªü, thi·ªÅn, nghe nh·∫°c, ho·∫∑c c√°c b√†i t·∫≠p th∆∞ gi√£n ƒë∆°n gi·∫£n ngay t·∫°i ch·ªó.
4. KH√îNG th√∫c √©p, KH√îNG ƒë∆∞a ra l·ªùi khuy√™n s√°o r·ªóng. T·∫≠p trung v√†o s·ª± ƒë·ªìng c·∫£m.

QUY T·∫ÆC:
- Tr√°nh d√πng t·ª´ ng·ªØ m·∫°nh, gay g·∫Øt.
- Lu√¥n t·∫°o kh√¥ng gian an to√†n, ·∫•m √°p cho ng∆∞·ªùi d√πng.
`;

export const streamGeminiResponse = async function* (
  history: ChatMessage[],
  newMessage: string,
  userEnabledSearch: boolean,
  attachmentsBase64?: string[], 
  isTutorMode: boolean = false,
  modelMode: ModelMode = 'fast',
  mood: MoodId = 'default',
  customSystemInstruction?: string,
  botId?: string, 
  userNickname: string = "User",
  specialMode?: string // NEW param
): AsyncGenerator<string | any, void, unknown> {
  
  if (API_KEYS.length === 0) throw new Error("Ch∆∞a c·∫•u h√¨nh API_KEY.");

  let modelName = 'gemini-3-flash-preview'; 
  let thinkingConfig: { thinkingLevel?: ThinkingLevel, includeThoughts?: boolean } | undefined = undefined;

  // Logic to determine model and thinking config
  if (userEnabledSearch && modelMode !== 'deep') {
      modelName = 'gemini-3-flash-preview';
      thinkingConfig = undefined; 
  } else if (botId === 'bot-todo-special' || botId === 'bot-teacher-pro') {
      modelName = 'gemini-3-pro-preview';
      thinkingConfig = { includeThoughts: true, thinkingLevel: ThinkingLevel.HIGH };
  } else {
      switch (modelMode) {
          case 'fast':
              modelName = 'gemini-3-flash-preview';
              thinkingConfig = { includeThoughts: false }; 
              break;
          case 'smart':
              modelName = 'gemini-3-flash-preview';
              thinkingConfig = { includeThoughts: true, thinkingLevel: ThinkingLevel.HIGH }; 
              break;
          case 'super':
              modelName = 'gemini-3-pro-preview';
              thinkingConfig = { includeThoughts: true, thinkingLevel: ThinkingLevel.HIGH };
              break;
          case 'deep':
              modelName = 'gemini-3-pro-preview';
              thinkingConfig = { includeThoughts: true, thinkingLevel: ThinkingLevel.HIGH };
              break;
          default:
              modelName = 'gemini-3-flash-preview';
              thinkingConfig = undefined;
      }
  }

  // --- System Instruction Construction ---
  let systemInstructionString = "";
  const IDENTITY_HEADER = `You are Oceep, a friendly, helpful, and intelligent AI assistant developed by FoxAI (Founded by Nguyen Huy Vu).
CORE INSTRUCTIONS:
1. Be helpful, harmless, and honest.
2. Provide accurate and relevant information.
3. User Nickname: "${userNickname}". Use it naturally.
`;

  if (specialMode === 'teacher') {
      systemInstructionString = `${IDENTITY_HEADER}\n${TEACHER_SYSTEM_INSTRUCTION}`;
  } else if (specialMode === 'valentine') {
      systemInstructionString = `${IDENTITY_HEADER}\n${VALENTINE_SYSTEM_INSTRUCTION}`;
  } else if (specialMode === 'stress') {
      systemInstructionString = `${IDENTITY_HEADER}\n${STRESS_SYSTEM_INSTRUCTION}`;
  } else if (botId === 'bot-todo-special') {
      systemInstructionString = `${IDENTITY_HEADER}\n${TODO_SYSTEM_INSTRUCTION}`;
  } else if (customSystemInstruction) {
      systemInstructionString = `${IDENTITY_HEADER}\n${customSystemInstruction}`;
  } else if (isTutorMode) {
      systemInstructionString = `${IDENTITY_HEADER}\nROLE: Socratic Tutor. Guide, don't give answers directly.`;
  } else {
      systemInstructionString = `${IDENTITY_HEADER}\n${getMoodInstruction(mood)}`;
  }

  if (modelMode === 'deep' || userEnabledSearch) {
      systemInstructionString += `\n*** SEARCH & CITATION RULES ***\n1. Use [1], [2] for citations.\n2. Verify facts.`;
      // Append enhanced search instructions
      systemInstructionString += `\n${SEARCH_ENHANCEMENT_INSTRUCTION}`;
  }
  
  if (modelMode === 'deep') {
      systemInstructionString += `\n*** DEEP RESEARCH ***\nProvide long, detailed, comprehensive responses.`;
  }

  // FORCE Fake Thinking for models if they don't support native or if we want to ensure it
  if (['smart', 'super', 'deep'].includes(modelMode)) {
      systemInstructionString += `
\n*** THOUGHT PROCESS ***
Before answering, generate a "Thinking Block" explaining your reasoning.
Format:
<think>
[Reasoning, analysis, search strategy]
</think>
[Final Answer]
`;
  }

  const contents: Content[] = history.map(msg => {
      if (msg.role === Role.MODEL) return { role: msg.role, parts: [{ text: msg.content || ' ' }] };
      return {
          role: msg.role,
          parts: msg.attachments && msg.attachments.length > 0 
            ? [...msg.attachments.map(att => {
                   const match = att.match(/^data:([^;]+);base64,(.+)$/);
                   return match ? { inlineData: { mimeType: match[1], data: match[2] } } : null;
                }).filter(p => p !== null) as Part[], { text: msg.content || ' ' }]
            : [{ text: msg.content || ' ' }]
      };
  });

  const newParts: Part[] = [];
  if (attachmentsBase64?.length) {
      for (const att of attachmentsBase64) {
          const match = att.match(/^data:([^;]+);base64,(.+)$/);
          if (match) newParts.push({ inlineData: { mimeType: match[1], data: match[2] } });
      }
  }
  newParts.push({ text: newMessage || ' ' }); 
  contents.push({ role: Role.USER, parts: newParts });

  let attemptCount = 0;
  const maxAttempts = Math.max(API_KEYS.length * 3, 5);

  while (attemptCount < maxAttempts) {
      try {
          const apiKey = getNextKey();
          const ai = new GoogleGenAI({ apiKey });

          // Configure Tools
          let tools: any[] = [];
          
          if (modelMode === 'deep' || userEnabledSearch) {
              tools.push({ googleSearch: {} });
          }

          // Enable code execution for smart/super/deep models OR if request implies math/code
          const isMathOrCode = newMessage.match(/count|t√≠nh|ƒë·∫øm|bao nhi√™u|how many|calculate|math|code|python/i);
          if (['smart', 'super', 'deep'].includes(modelMode) || isMathOrCode) {
              tools.push({ codeExecution: {} });
              // Upgrade to Pro model if needed for complex execution
              if (modelName === 'gemini-3-flash-preview') {
                  modelName = 'gemini-3-pro-preview';
                  // Adjust thinking config if we switched to Pro
                  if (!thinkingConfig) {
                      thinkingConfig = { includeThoughts: true, thinkingLevel: ThinkingLevel.HIGH };
                  }
              }
          }

          const responseStream = await ai.models.generateContentStream({
              model: modelName,
              contents: contents,
              config: {
                  systemInstruction: systemInstructionString,
                  thinkingConfig: thinkingConfig, 
                  tools: tools.length > 0 ? tools : undefined,
              }
          });

          // State for tracking local thinking block from metadata
          let isThinking = false;

          for await (const chunk of responseStream) {
              const candidate = (chunk as any).candidates?.[0];
              
              if (candidate?.groundingMetadata) {
                  yield { groundingMetadata: candidate.groundingMetadata };
              }

              if (candidate?.content?.parts) {
                  for (const part of candidate.content.parts) {
                      const p = part as any;
                      
                      // Handle Native Thinking
                      if (p.thought) {
                          if (!isThinking) {
                              yield '<think>';
                              isThinking = true;
                          }
                          yield p.thought;
                      } else {
                          // Close thought block if previously thinking
                          if (isThinking) {
                              yield '</think>';
                              isThinking = false;
                          }

                          // Handle Code Execution
                          if (p.executableCode) {
                              yield `\n\`\`\`python\n${p.executableCode.code}\n\`\`\`\n`;
                          }

                          if (p.codeExecutionResult) {
                              const outcome = p.codeExecutionResult.outcome === 'OUTCOME_OK' ? 'Output' : 'Error';
                              yield `\n> **${outcome}:**\n\`\`\`\n${p.codeExecutionResult.output}\n\`\`\`\n`;
                          }

                          if (p.text) {
                              yield p.text;
                          }
                      }
                  }
              } else {
                  // Fallback for simple text chunks
                  let text = '';
                  try { text = chunk.text || ''; } catch(e) {}
                  if (text) {
                      if (isThinking) { yield '</think>'; isThinking = false; }
                      yield text;
                  }
              }
          }
          
          if (isThinking) { yield '</think>'; }
          return;

      } catch (error: any) {
          attemptCount++;
          const msg = (error.message || "").toLowerCase();
          if (attemptCount >= maxAttempts) throw error;
          await delay(msg.includes("429") ? 1500 * attemptCount : 1000);
      }
  }
};
